{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "amazon_reviews_bert_tf.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6EdeJ0RuMab",
        "colab_type": "text"
      },
      "source": [
        "# Text Classification with BERT\n",
        "BERT (Bidirectional Encoder Representations from Transformers) is a recent [paper](https://arxiv.org/pdf/1810.04805.pdf) published by researchers at Google AI Language. It has caused a stir in the Machine Learning community by presenting state-of-the-art results in a wide variety of NLP tasks, including Question Answering (SQuAD v1.1), Natural Language Inference (MNLI), and others.  \n",
        "BERT is based on the Transformer architecture. To know more about Transformer, please refer this amazing [blog](http://jalammar.github.io/illustrated-transformer/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glgcdgb_gRFl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bl4c0l6Jv9JJ",
        "colab_type": "text"
      },
      "source": [
        "### Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZ0hO9KVgSpz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "2143eb7f-95b7-4a8c-932b-ad2ccf068dfa"
      },
      "source": [
        "!pip install bert-tensorflow\n",
        "!pip install tqdm\n",
        "!pip install tensorflow_hub"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting contractions\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/2a/ba0a3812e2a1de2cc4ee0ded0bdb750a7cef1631c13c78a4fc4ab042adec/contractions-0.0.21-py2.py3-none-any.whl\n",
            "Installing collected packages: contractions\n",
            "Successfully installed contractions-0.0.21\n",
            "Collecting bert-tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/66/7eb4e8b6ea35b7cc54c322c816f976167a43019750279a8473d355800a93/bert_tensorflow-1.0.1-py2.py3-none-any.whl (67kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 4.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.12.0)\n",
            "Installing collected packages: bert-tensorflow\n",
            "Successfully installed bert-tensorflow-1.0.1\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.28.1)\n",
            "Requirement already satisfied: tensorflow_hub in /usr/local/lib/python3.6/dist-packages (0.5.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_hub) (1.16.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_hub) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_hub) (3.7.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow_hub) (41.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMFHv4iagf7E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as tf_hub\n",
        "import time\n",
        "import numpy as np\n",
        "import os\n",
        "from bert.tokenization import FullTokenizer\n",
        "import tqdm\n",
        "from tensorflow.keras import backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.INFO)\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "tf.set_random_seed(SEED)\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psby2HwhgqBC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9612007f-6766-4993-8d54-c42884135684"
      },
      "source": [
        "print(tf.__version__)\n",
        "print(tf_hub.__version__)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.14.0\n",
            "0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KN2RxOygtCD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "696398d6-7e8c-45b1-ad19-06dc5ecdd97a"
      },
      "source": [
        "print(tf.test.is_gpu_available())\n",
        "print(tf.test.gpu_device_name())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "/device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5a8amu8wFxZ",
        "colab_type": "text"
      },
      "source": [
        "### Load the Dataset\n",
        "The dataset I have used is a small dataset containing only 10000 rows from the amazon fine reviews dataset. You can use the full dataset for training but it will require a huge amount of time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMaHAd5bgyT5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "6a22d7c9-7cb3-45d3-96e4-1d7fcf1ecb2d"
      },
      "source": [
        "dataset = pd.read_csv('/content/drive/My Drive/Colab Notebooks/sample_amazon_reviews.csv')\n",
        "dataset.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This food is the best.  Our golden retriever w...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I finally found a jarred pasta sauce I love! B...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>All the box of milk came intact. The taste of ...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>This was the only treat my dog liked during ob...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I was very excited about this pasta. I have be...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text Sentiment\n",
              "0  This food is the best.  Our golden retriever w...  Positive\n",
              "1  I finally found a jarred pasta sauce I love! B...  Positive\n",
              "2  All the box of milk came intact. The taste of ...  Negative\n",
              "3  This was the only treat my dog liked during ob...  Positive\n",
              "4  I was very excited about this pasta. I have be...  Negative"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1YzbmFvhI_U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "4e350835-97f2-4a19-b7bb-184d2bf59af1"
      },
      "source": [
        "dataset.info()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 2 columns):\n",
            "Text         10000 non-null object\n",
            "Sentiment    10000 non-null object\n",
            "dtypes: object(2)\n",
            "memory usage: 156.3+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iipyteGPhMAB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "796b25bd-5586-48ee-a081-cb4cddfcee82"
      },
      "source": [
        "dataset['Sentiment'] = [1 if sentiment == 'Positive' else 0 \n",
        "                            for sentiment in dataset['Sentiment'].values]\n",
        "dataset.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This food is the best.  Our golden retriever w...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I finally found a jarred pasta sauce I love! B...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>All the box of milk came intact. The taste of ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>This was the only treat my dog liked during ob...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I was very excited about this pasta. I have be...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  Sentiment\n",
              "0  This food is the best.  Our golden retriever w...          1\n",
              "1  I finally found a jarred pasta sauce I love! B...          1\n",
              "2  All the box of milk came intact. The taste of ...          0\n",
              "3  This was the only treat my dog liked during ob...          1\n",
              "4  I was very excited about this pasta. I have be...          0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqkoG3BahX4n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "afa72e79-70b7-414d-b42e-2c982ecad424"
      },
      "source": [
        "train_df = dataset.iloc[:8000]\n",
        "val_df = dataset.iloc[8000:9000]\n",
        "test_df = dataset.iloc[9000:]\n",
        "\n",
        "train_df.shape, val_df.shape, test_df.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8000, 2), (1000, 2), (1000, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8JcMSZGh2Td",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_text = train_df['Text'].tolist()\n",
        "train_labels = train_df['Sentiment'].tolist()\n",
        "\n",
        "val_text = val_df['Text'].tolist()\n",
        "val_labels = val_df['Sentiment'].tolist()\n",
        "\n",
        "test_text = test_df['Text'].tolist()\n",
        "test_labels = test_df['Sentiment'].tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7gyFeyKw3Vz",
        "colab_type": "text"
      },
      "source": [
        "### BERT Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlSxpkNmiA7C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PaddingInputExample(object):\n",
        "  pass\n",
        "    \n",
        "    \n",
        "class InputExample(object):\n",
        "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
        "\n",
        "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
        "        \n",
        "        \"\"\"Constructs a InputExample.\n",
        "    Args:\n",
        "      guid: Unique id for the example.\n",
        "      text_a: string. The untokenized text of the first sequence. For single\n",
        "        sequence tasks, only this sequence must be specified.\n",
        "      text_b: (Optional) string. The untokenized text of the second sequence.\n",
        "        Only must be specified for sequence pair tasks.\n",
        "      label: (Optional) string. The label of the example. This should be\n",
        "        specified for train and dev examples, but not for test examples.\n",
        "    \"\"\"\n",
        "        self.guid = guid\n",
        "        self.text_a = text_a\n",
        "        self.text_b = text_b\n",
        "        self.label = label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbkGg_V-iRKL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_tokenizer_from_hub_module(bert_path):\n",
        "    \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
        "    bert_module =  tf_hub.Module(bert_path)\n",
        "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
        "    vocab_file, do_lower_case = sess.run(\n",
        "        [\n",
        "            tokenization_info[\"vocab_file\"],\n",
        "            tokenization_info[\"do_lower_case\"],\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfYhmCgDidxF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_text_to_examples(texts, labels):\n",
        "    \"\"\"Create InputExamples\"\"\"\n",
        "    InputExamples = []\n",
        "    for text, label in zip(texts, labels):\n",
        "        InputExamples.append(\n",
        "            InputExample(guid=None, text_a=text, text_b=None, label=label)\n",
        "        )\n",
        "    return InputExamples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrwYFt8EioNw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_single_example(tokenizer, example, max_seq_length=256):\n",
        "    \"\"\"Converts a single `InputExample` into a single `InputFeatures`.\"\"\"\n",
        "\n",
        "    if isinstance(example, PaddingInputExample):\n",
        "        input_ids = [0] * max_seq_length\n",
        "        input_mask = [0] * max_seq_length\n",
        "        segment_ids = [0] * max_seq_length\n",
        "        label = 0\n",
        "        return input_ids, input_mask, segment_ids, label\n",
        "\n",
        "    tokens_a = tokenizer.tokenize(example.text_a)\n",
        "    if len(tokens_a) > max_seq_length - 2:\n",
        "        tokens_a = tokens_a[0 : (max_seq_length - 2)]\n",
        "\n",
        "    tokens = []\n",
        "    segment_ids = []\n",
        "    tokens.append(\"[CLS]\")\n",
        "    segment_ids.append(0)\n",
        "    for token in tokens_a:\n",
        "        tokens.append(token)\n",
        "        segment_ids.append(0)\n",
        "    tokens.append(\"[SEP]\")\n",
        "    segment_ids.append(0)\n",
        "\n",
        "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "    # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
        "    # tokens are attended to.\n",
        "    input_mask = [1] * len(input_ids)\n",
        "\n",
        "    # Zero-pad up to the sequence length.\n",
        "    while len(input_ids) < max_seq_length:\n",
        "        input_ids.append(0)\n",
        "        input_mask.append(0)\n",
        "        segment_ids.append(0)\n",
        "    assert len(input_ids) == max_seq_length\n",
        "    assert len(input_mask) == max_seq_length\n",
        "    assert len(segment_ids) == max_seq_length\n",
        "\n",
        "    return input_ids, input_mask, segment_ids, example.label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Usrs9cI6i4mG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_examples_to_features(tokenizer, examples, max_seq_length=256):\n",
        "    \"\"\"Convert a set of `InputExample`s to a list of `InputFeatures`.\"\"\"\n",
        "\n",
        "    input_ids, input_masks, segment_ids, labels = [], [], [], []\n",
        "    for example in tqdm.tqdm(examples, desc=\"Converting examples to features\"):\n",
        "        input_id, input_mask, segment_id, label = convert_single_example(\n",
        "            tokenizer, example, max_seq_length\n",
        "        )\n",
        "        input_ids.append(input_id)\n",
        "        input_masks.append(input_mask)\n",
        "        segment_ids.append(segment_id)\n",
        "        labels.append(label)\n",
        "    return (\n",
        "        np.array(input_ids),\n",
        "        np.array(input_masks),\n",
        "        np.array(segment_ids),\n",
        "        np.array(labels).reshape(-1, 1),\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3zlumVDi9gV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize session\n",
        "sess = tf.Session()\n",
        "\n",
        "# Params for bert model and tokenization\n",
        "BERT_PATH = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
        "MAX_SEQ_LENGTH = 512"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwMl8cmHjCy0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "71b7c213-2377-49db-d2cc-36ae4c0835fa"
      },
      "source": [
        "# Instantiate tokenizer\n",
        "tokenizer = create_tokenizer_from_hub_module(bert_path=BERT_PATH)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "I0824 16:55:37.982342 140297130354560 saver.py:1499] Saver not created because there are no variables in the graph to restore\n",
            "W0824 16:55:39.835515 140297130354560 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoSxJwaOjfx6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert data to InputExample format\n",
        "train_examples = convert_text_to_examples(train_text, train_labels)\n",
        "val_examples = convert_text_to_examples(val_text, val_labels)\n",
        "test_examples = convert_text_to_examples(test_text, test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvlgYc1Ojui8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "486f7e6f-4613-4468-e2f6-0801cdaf3fb9"
      },
      "source": [
        "(train_input_ids, train_input_masks, \n",
        " train_segment_ids, train_labels) =  convert_examples_to_features(tokenizer=tokenizer, \n",
        "                                                                  examples=train_examples, \n",
        "                                                                  max_seq_length=MAX_SEQ_LENGTH)\n",
        "\n",
        "(val_input_ids, val_input_masks, \n",
        " val_segment_ids, val_labels) =  convert_examples_to_features(tokenizer=tokenizer, \n",
        "                                                              examples=val_examples, \n",
        "                                                              max_seq_length=MAX_SEQ_LENGTH)\n",
        "\n",
        "(test_input_ids, test_input_masks, \n",
        " test_segment_ids, test_labels) =  convert_examples_to_features(tokenizer=tokenizer, \n",
        "                                                                examples=test_examples, \n",
        "                                                                max_seq_length=MAX_SEQ_LENGTH)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Converting examples to features: 100%|██████████| 8000/8000 [00:10<00:00, 759.01it/s]\n",
            "Converting examples to features: 100%|██████████| 1000/1000 [00:01<00:00, 771.15it/s]\n",
            "Converting examples to features: 100%|██████████| 1000/1000 [00:01<00:00, 788.91it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJ5M0ZbOj5dl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "162164a2-57fb-4748-a83c-fa7c404158bd"
      },
      "source": [
        "train_input_ids.shape, val_input_ids.shape, test_input_ids.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8000, 512), (1000, 512), (1000, 512))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LPalgvmkAHo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "80d6bb7d-a4ef-4f64-b54c-443079c1f04e"
      },
      "source": [
        "bm = tf_hub.Module(BERT_PATH, trainable=True, name=f\"bert_module\")\n",
        "bm"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_hub.module.Module at 0x7f98c5dadcf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIU-XvXlxDhg",
        "colab_type": "text"
      },
      "source": [
        "### Build BERT Model for Text Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FakZVh3kE2N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertLayer(tf.keras.layers.Layer):\n",
        "    \n",
        "    def __init__(self, bert_path, n_fine_tune_encoders=10, **kwargs,):\n",
        "        \n",
        "        self.n_fine_tune_encoders = n_fine_tune_encoders\n",
        "        self.trainable = True\n",
        "        self.output_size = 768\n",
        "        self.bert_path = bert_path\n",
        "        super(BertLayer, self).__init__(**kwargs)\n",
        "\n",
        "        \n",
        "    def build(self, input_shape):\n",
        "        self.bert = tf_hub.Module(self.bert_path,\n",
        "                                  trainable=self.trainable, \n",
        "                                  name=f\"{self.name}_module\")\n",
        "\n",
        "        # Remove unused layers\n",
        "        trainable_vars = self.bert.variables\n",
        "        trainable_vars = [var for var in trainable_vars \n",
        "                                  if not \"/cls/\" in var.name]\n",
        "        trainable_layers = [\"embeddings\", \"pooler/dense\"]\n",
        "\n",
        "\n",
        "        # Select how many layers to fine tune\n",
        "        for i in range(self.n_fine_tune_encoders+1):\n",
        "            trainable_layers.append(f\"encoder/layer_{str(10 - i)}\")\n",
        "\n",
        "        # Update trainable vars to contain only the specified layers\n",
        "        trainable_vars = [var for var in trainable_vars\n",
        "                                  if any([l in var.name \n",
        "                                              for l in trainable_layers])]\n",
        "\n",
        "        # Add to trainable weights\n",
        "        for var in trainable_vars:\n",
        "            self._trainable_weights.append(var)\n",
        "\n",
        "        for var in self.bert.variables:\n",
        "            if var not in self._trainable_weights:# and 'encoder/layer' not in var.name:\n",
        "                self._non_trainable_weights.append(var)\n",
        "        print('Trainable layers:', len(self._trainable_weights))\n",
        "        print('Non Trainable layers:', len(self._non_trainable_weights))\n",
        "\n",
        "        super(BertLayer, self).build(input_shape)\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        \n",
        "        inputs = [K.cast(x, dtype=\"int32\") for x in inputs]\n",
        "        input_ids, input_mask, segment_ids = inputs\n",
        "        bert_inputs = dict(input_ids=input_ids, \n",
        "                           input_mask=input_mask, \n",
        "                           segment_ids=segment_ids)\n",
        "        \n",
        "        pooled = self.bert(inputs=bert_inputs, \n",
        "                           signature=\"tokens\", \n",
        "                           as_dict=True)[\"pooled_output\"]\n",
        "\n",
        "        return pooled\n",
        "\n",
        "    \n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0], self.output_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "st54P9OCkfha",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build model\n",
        "def build_model(bert_path, max_seq_length, n_fine_tune_encoders=10): \n",
        "    \n",
        "    inp_id = tf.keras.layers.Input(shape=(max_seq_length,), name=\"input_ids\")\n",
        "    inp_mask = tf.keras.layers.Input(shape=(max_seq_length,), name=\"input_masks\")\n",
        "    inp_segment = tf.keras.layers.Input(shape=(max_seq_length,), name=\"segment_ids\")\n",
        "    bert_inputs = [inp_id, inp_mask, inp_segment]\n",
        "    \n",
        "    bert_output = BertLayer(bert_path=bert_path, \n",
        "                            n_fine_tune_encoders=n_fine_tune_encoders)(bert_inputs)\n",
        "    \n",
        "    dense = tf.keras.layers.Dense(256, activation='relu')(bert_output)\n",
        "    pred = tf.keras.layers.Dense(1, activation='sigmoid')(dense)\n",
        "    \n",
        "    model = tf.keras.models.Model(inputs=bert_inputs, outputs=pred)\n",
        "    model.compile(loss='binary_crossentropy', \n",
        "                  optimizer=tf.keras.optimizers.Adam(lr=2e-5), \n",
        "                  metrics=['accuracy'])    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31k9NJATlAk8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize_vars(sess):\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    sess.run(tf.tables_initializer())\n",
        "    K.set_session(sess)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15g5oRAUlEL7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "0927edaa-b0f0-47d4-bf20-c0ed7491ba38"
      },
      "source": [
        "model = build_model(bert_path=BERT_PATH, max_seq_length=MAX_SEQ_LENGTH, n_fine_tune_encoders=10)\n",
        "\n",
        "initialize_vars(sess)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trainable layers: 199\n",
            "Non Trainable layers: 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0824 17:02:44.192648 140297130354560 saver.py:1499] Saver not created because there are no variables in the graph to restore\n",
            "W0824 17:02:49.166233 140297130354560 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0824 17:02:49.224421 140297130354560 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LECCLz4FlI5j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "2ddd1bdd-2f8f-435f-89d8-1dcecef08f57"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_ids (InputLayer)          [(None, 512)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_masks (InputLayer)        [(None, 512)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "segment_ids (InputLayer)        [(None, 512)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bert_layer (BertLayer)          (None, 768)          110104890   input_ids[0][0]                  \n",
            "                                                                 input_masks[0][0]                \n",
            "                                                                 segment_ids[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 256)          196864      bert_layer[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            257         dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 110,302,011\n",
            "Trainable params: 109,679,361\n",
            "Non-trainable params: 622,650\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lL1LzfuxNyA",
        "colab_type": "text"
      },
      "source": [
        "### Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m43TLKlIlRl0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "edd43d0f-23be-4836-eca0-dbd3b850ce8c"
      },
      "source": [
        "model.fit(\n",
        "    [train_input_ids, train_input_masks, train_segment_ids], \n",
        "    train_labels,\n",
        "    validation_data=([val_input_ids, val_input_masks, val_segment_ids], val_labels),\n",
        "    epochs=2,\n",
        "    batch_size=8,\n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 8000 samples, validate on 1000 samples\n",
            "Epoch 1/2\n",
            "8000/8000 [==============================] - 994s 124ms/sample - loss: 0.3102 - acc: 0.8643 - val_loss: 0.2486 - val_acc: 0.9100\n",
            "Epoch 2/2\n",
            "8000/8000 [==============================] - 991s 124ms/sample - loss: 0.1235 - acc: 0.9585 - val_loss: 0.2607 - val_acc: 0.8910\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f98a67a3710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wn4nNvhpxWGj",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate the model on TEST Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aY_Upp17lZ7Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "37ccd67a-ee7c-4009-c4af-6bae3ad45391"
      },
      "source": [
        "test_predictions = model.predict(x=[test_input_ids, \n",
        "                                    test_input_masks, \n",
        "                                    test_segment_ids],\n",
        "                                 batch_size=64,\n",
        "                                 verbose=1)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 46s 46ms/sample\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwclaoN-tlQk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_predictions = test_predictions.ravel()\n",
        "test_pred_labels = [1 if prob > 0.5 else 0 for prob in test_predictions]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j87TbSghtxbm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "41905631-19d8-4167-b179-70e679f9a2f3"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "print('Classification Report:')\n",
        "print(classification_report(y_true=test_labels, y_pred=test_pred_labels))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.93      0.90       493\n",
            "           1       0.93      0.87      0.90       507\n",
            "\n",
            "    accuracy                           0.90      1000\n",
            "   macro avg       0.90      0.90      0.90      1000\n",
            "weighted avg       0.90      0.90      0.90      1000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_qv5ztztzzM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "86e9e6b4-e40f-4676-8a5a-93791ae35d6e"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "with tf.Session() as session:\n",
        "    cm = tf.confusion_matrix(test_labels, test_pred_labels).eval()\n",
        "\n",
        "LABELS = ['Negative', 'Positive']\n",
        "sns.heatmap(cm, annot=True, xticklabels=LABELS, yticklabels=LABELS, fmt='g')\n",
        "xl = plt.xlabel(\"Predicted\")\n",
        "yl = plt.ylabel(\"Actuals\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEKCAYAAAAyx7/DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6AVaSSv9DQcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJ97FRHnt_1k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}